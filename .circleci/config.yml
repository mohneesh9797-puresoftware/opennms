version: 2.1


executors:
  centos-build-executor:
    docker:
      - image: opennms/build-env:1.8.0.232.b09-3.6.2-b3291
  debian-build-executor:
    docker:
      - image: opennms/build-env:debian-jdk8-b3572
  docker-executor:
    docker:
      - image: docker:19.03.0-git
  integration-test-executor:
    machine: true
  smoke-test-executor:
    machine:
      image: ubuntu-1604:201903-01

# NOTE: the "_label" versions of these are for the case when your source or target
# branches have slashes in them, that way the merge branch gets created properly
defaults: &defaults
  parameters:
    previous_branch:
      description: the previous branch, if any
      type: string
      default: ranger/foundation-2016
    previous_branch_label:
      description: the previous branch, if any (escaped, no slashes)
      type: string
      default: ranger-foundation-2016
    main_branch:
      description: the auto-merge main branch
      type: string
      default: ranger/foundation-2017
    main_branch_label:
      description: the auto-merge main branch (escaped, no slashes)
      type: string
      default: ranger-foundation-2017
    next_branch:
      description: the auto-merge target branch
      type: string
      default: ranger/foundation-2018
    next_branch_label:
      description: the auto-merge target branch (escaped, no slashes)
      type: string
      default: ranger-foundation-2018

docker_container_config: &docker_container_config
  executor: docker-executor

orbs:
  cloudsmith: cloudsmith/cloudsmith@1.0.3
  sign-packages: opennms/sign-packages@2.1.1

commands:
  cached-checkout:
      description: "Checkout with caching"
      steps:
        - restore_cache:
            keys:
              - source-v1-{{ .Branch }}-{{ .Revision }}
              - source-v1-{{ .Branch }}-
              - source-v1-
        - checkout
        - run:
            name: git fetch origin
            command: |
              git fetch origin
        - save_cache:
            key: source-v1-{{ .Branch }}-{{ .Revision }}
            paths:
              - ".git"
  restore-maven-cache:
      description: "Maven: Calculate cache key and restore cache"
      steps:
        - run:
            name: Calculate cache key from pom files
            command: |
              find . -type f -name "pom.xml" -exec sha256sum "{}" \; | sort -nr >> maven-dependency-cache.key
        - restore_cache:
            keys:
              - maven-dependencies-v2-{{ checksum "maven-dependency-cache.key" }}
              - maven-dependencies-v2-
        - run:
            name: Remove OpenNMS artifacts from cache
            command: |
              rm -rf ~/.m2/repository/org/opennms
  save-maven-cache:
    description: "Maven: Save cache"
    steps:
      - save_cache:
          key: maven-dependencies-v2-{{ checksum "maven-dependency-cache.key" }}
          paths:
            - ~/.m2
  restore-nodejs-cache:
      description: "NodeJS: Calculate cache key and restore cache"
      steps:
        - run:
            name: Calculate cache key
            command: |
              sha256sum opennms-webapp/bower.json > nodejs-dependency-cache.key
              sha256sum opennms-webapp/package.json >> nodejs-dependency-cache.key
        - restore_cache:
            keys:
              - nodejs-dependencies-v1-{{ checksum "nodejs-dependency-cache.key" }}
              - nodejs-dependencies-v1-
  save-nodejs-cache:
    description: "NodeJS: Save cache"
    steps:
      - save_cache:
          key: nodejs-dependencies-v1-{{ checksum "nodejs-dependency-cache.key" }}
          paths:
            - opennms-webapp/bower_components
            - opennms-webapp/node_modules
  restore-sonar-cache:
      description: "Sonar: Restore sonar cache"
      steps:
        - restore_cache:
            keys:
              - sonar-cache-v1-
  save-sonar-cache:
      description: "Sonar: Save sonar cache"
      steps:
        - save_cache:
            key: sonar-cache-v1-
            paths:
              - ~/.sonar
  dockerhub-login:
    description: "Connect to DockerHub"
    steps:
      - run:
          name: Login to DockerHub
          command: |
            docker login -u ${DOCKERHUB_LOGIN} -p ${DOCKERHUB_PASS}
  run-smoke-tests:
    description: "Run the smoke tests"
    parameters:
      minimal:
        default: false
        type: boolean
    steps:
      - run:
          name: Enable swap
          command: |
            sudo fallocate -l 8G /swapfile
            sudo chmod 600 /swapfile
            sudo mkswap /swapfile
            sudo swapon /swapfile
            sudo sysctl vm.swappiness=5
            cat /proc/sys/vm/swappiness
      - run:
          name: Load Horizon OCI image
          command: |
            cd opennms-container/horizon
            docker image load -i images/container.oci
      - run:
          name: Load Minion OCI image
          command: |
            cd opennms-container/minion
            docker image load -i images/container.oci
      - run:
          name: Monitor JVM processes
          background: true
          command: |
            .circleci/scripts/jvmprocmon-start.sh
      - run:
          name: Monitor memory usage
          background: true
          command: |
            free -m -c 500 -s 30
      - run:
          name: Smoke Tests
          no_output_timeout: 30m
          command: |
            .circleci/scripts/smoke.sh << parameters.minimal >>
      - run:
          name: Gather system logs
          when: always
          command: |
            mkdir -p ~/test-results/system-logs
            dmesg > ~/test-results/system-logs/dmesg
            ps auxf > ~/test-results/system-logs/ps
            free -m > ~/test-results/system-logs/free
            docker stats --no-stream > ~/test-results/system-logs/docker_stats
            cp -R /tmp/jvmprocmon ~/test-results/system-logs/
            ls -alh ~/project/smoke-test/
      - run:
          name: Gather test artifacts
          when: always
          command: |
            mkdir -p ~/test-results/junit
            find . -type f -regex ".*/target/surefire-reports/.*xml" -exec cp {} ~/test-results/junit/ \;
            find . -type f -regex ".*/target/failsafe-reports/.*xml" -exec cp {} ~/test-results/junit/ \;
            mkdir -p ~/test-artifacts/recordings
            cp -R ~/project/smoke-test/target/*.flv ~/test-artifacts/recordings || true
            cp -R ~/project/smoke-test/target/screenshots ~/test-artifacts/ || true
            cp -R ~/project/smoke-test/target/logs ~/test-artifacts/ || true
      - store_test_results:
          path: ~/test-results
      - store_artifacts:
          when: always
          path: ~/test-results
          destination: test-results
      - store_artifacts:
          when: always
          path: ~/test-artifacts
          destination: test-artifacts
  run-build:
    description: "Run the main build"
    parameters:
      number-vcpu:
        default: 8
        type: integer
      node-memory:
        default: echo "NODE_OPTIONS Not Set"
        type: string
      vaadin-javamaxmem:
        default: 1g
        type: string
    steps:
      - cached-checkout
      - restore-maven-cache
      - restore-nodejs-cache
      - run:
          name: Compile OpenNMS
          command: |
            .circleci/scripts/configure-signing.sh
            mvn clean -DskipTests=true
            << parameters.node-memory >>
            ./compile.pl -DskipTests=true -Dbuild.skip.tarball=true \
              -DvaadinJavaMaxMemory=<< parameters.vaadin-javamaxmem >> \
              -DmaxCpus=<< parameters.number-vcpu >> \
              install --builder smart --threads << parameters.number-vcpu >>
      - run:
          name: Compile smoke tests
            # Compile the smoke tests, but don't run them yet
            # We want to make sure that they compile and also leverage the caching that is setup here
            # so that the artifacts required to run the smoke tests are cached as well without the need
            # to maintain another cache
          command: |
            cd smoke-test && mvn install -DskipTests=true -DskipITs=true
      - save-maven-cache
      - save-nodejs-cache
      - persist_to_workspace:
          root: ~/
          paths:
            - project
            - .m2
  run-integration-tests:
    parameters:
      run-code-coverage:
        default: false
        type: boolean
      rerun-failtest-count:
        default: 0
        type: integer
      failure-option:
        default: -fae
        type: string
      changes-only:
        default: true
        type: boolean
    steps:
      - run:
          name: Integration Tests
          no_output_timeout: 1.0h
          command: |
            export CCI_CODE_COVERAGE=<< parameters.run-code-coverage >>
            export CCI_RERUN_FAILTEST=<< parameters.rerun-failtest-count >>
            export CCI_FAILURE_OPTION=<< parameters.failure-option >>
            export CCI_CHANGES_ONLY=<< parameters.changes-only >>
            .circleci/scripts/itest.sh
      - run:
          name: Gather test results
          when: always
          command: |
            mkdir -p ~/test-results/junit
            find . -type f -regex ".*/target/surefire-reports-[0-9]+/.*xml" -exec cp {} ~/test-results/junit/ \;
            find . -type f -regex ".*/target/failsafe-reports-[0-9]+/.*xml" -exec cp {} ~/test-results/junit/ \;
      - run:
          name: Gather tests
          when: always
          command: |
            mkdir -p ~/generated-tests
            cp ./surefire_classname* ~/generated-tests/
            cp ./failsafe_classname* ~/generated-tests/
            cp /tmp/this_node* ~/generated-tests/
      - when:
          condition: << parameters.run-code-coverage >>
          steps:
            - run:
                name: Compress Target Directories (Code Coverage)
                when: always
                command: |
                  .circleci/scripts/codecoverage-save.sh
            - persist_to_workspace:
                root: ~/
                paths:
                  - code-coverage
      - store_test_results:
          path: ~/test-results
      - store_artifacts:
          when: always
          path: ~/test-results
          destination: test-results
      - store_artifacts:
          when: always
          path: ~/generated-tests
          destination: generated-tests
  publish-cloudsmith:
    steps:
      - cloudsmith/ensure-api-key
      - cloudsmith/install-cli
      - run:
          name: Publish Packages
          command: |
            .circleci/scripts/publish-cloudsmith.sh

workflows:
  weekly-coverage:
    triggers:
      - schedule:
          # Saturday at 12:00 AM
          cron: "0 0 * * 6"
          filters:
            branches:
              only:
                - develop
    jobs:
      - build
      - integration-test-with-coverage:
          requires:
            - build
      - code-coverage:
          requires:
            - integration-test-with-coverage
  build-deploy:
    <<: *defaults
    jobs:
      - build
      - horizon-rpm-build:
          requires:
            - build
      - minion-rpm-build:
          requires:
            - build
      - integration-test:
          requires:
            - build
      - smoke-test-full:
          requires:
            - horizon-rpm-build
            - minion-rpm-build
          filters:
            branches:
              only:
                - master
                - develop
                - /^release-.*/
                - /^foundation.*/
                - /^features.*/
                - /^merge-foundation\/.*/
                - /.*smoke.*/
      - smoke-test-minimal:
          requires:
            - horizon-rpm-build
            - minion-rpm-build
          filters:
            branches:
              ignore:
                - master
                - develop
                - /^release-.*/
                - /^foundation.*/
                - /^features.*/
                - /^merge-foundation\/.*/
                - /.*smoke.*/
      - horizon-publish-oci:
          requires:
            - horizon-rpm-build
          filters:
            branches:
              only:
                - master
                - develop
      - minion-publish-oci:
          requires:
            - minion-rpm-build
          filters:
            branches:
              only:
                - master
                - develop
      # These don't actually require `integration-test` but we shouldn't bother
      # spending cycles unless everything else passed
      - horizon-deb-build:
          requires:
            - integration-test
          filters:
            branches:
              only:
                - master
                - develop
                - /^release-.*/
                - /^foundation.*/
                - /^features.*/
                - /^merge-foundation\/.*/
                - /.*smoke.*/
      - create-merge-foundation-branch:
          # technically only requires the RPM/deb builds, but only publish
          # if everything passes
          requires:
            - horizon-deb-build
            - smoke-test-minimal
            - smoke-test-full
            - integration-test
          filters:
            branches:
              only: << parameters.main_branch >>
      - merge-foundation-branch:
          # technically only requires the RPM/deb builds, but only publish
          # if everything passes
          requires:
            - horizon-deb-build
            - smoke-test-full
          filters:
            branches:
              only: merge-foundation/<< parameters.previous_branch_label >>-to-<< parameters.main_branch_label >>
      - publish-cloudsmith:
          # technically only requires the RPM/deb builds, but only publish
          # if everything passes
          requires:
            - horizon-deb-build
            - smoke-test-full
          filters:
            branches:
              only:
                - master
                - develop
                - /^release-.*/
                - /^foundation.*/

jobs:
  build:
    executor: centos-build-executor
    # even without core/web-assets build, we need xlarge for vaadin
    resource_class: xlarge
    steps:
      - run-build:
          number-vcpu: 8
  horizon-rpm-build:
    executor: centos-build-executor
    # Larger memory footprint required to speed up builds using Takari smartbuilder
    resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - sign-packages/install-rpm-dependencies:
          skip_if_forked_pr: true
      - sign-packages/setup-env:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
      - run:
          name: Build RPMs
          command: |
            export NODE_OPTIONS=--max_old_space_size=1024
            export CCI_MAXCPU=4
            .circleci/scripts/makerpm.sh tools/packages/opennms/opennms.spec
      - sign-packages/sign-rpms:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
          gnupg_key: opennms@opennms.org
          packages: target/rpm/RPMS/noarch/*.rpm
      - setup_remote_docker:
          docker_layer_caching: true
      - run:
          name: Fetch RPM artifacts and build Horizon container image
          command: |
            cd opennms-container/horizon
            ./build_container_image.sh
      - store_artifacts:
          path: ~/project/opennms-container/horizon/images/container.oci
          destination: horizon.oci
      - store_artifacts:
          path: ~/project/target/rpm/RPMS/noarch
          destination: rpms
      - persist_to_workspace:
          root: ~/
          paths:
            - project/target/rpm/RPMS/noarch/
            - project/opennms-container/horizon/images/
  minion-rpm-build:
    executor: centos-build-executor
    # Larger memory footprint required to speed up builds using Takari smartbuilder
    # Will need to increase resource class if horizon-rpm-build is under 15 min
    resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - sign-packages/install-rpm-dependencies:
          skip_if_forked_pr: true
      - sign-packages/setup-env:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
      - run:
          name: Build RPMs
          command: |
            export NODE_OPTIONS=--max_old_space_size=1024
            export CCI_MAXCPU=4
            export CCI_VAADINJAVAMAXMEM=768m
            .circleci/scripts/makerpm.sh tools/packages/minion/minion.spec
      - sign-packages/sign-rpms:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
          gnupg_key: opennms@opennms.org
          packages: target/rpm/RPMS/noarch/*.rpm
      - setup_remote_docker:
          docker_layer_caching: true
      - run:
          name: Fetch RPM artifacts and build Minion container image
          command: |
            cd opennms-container/minion
            ./build_container_image.sh
      - store_artifacts:
          path: ~/project/opennms-container/minion/images/container.oci
          destination: minion.oci
      - store_artifacts:
          path: ~/project/target/rpm/RPMS/noarch
          destination: rpms
      - persist_to_workspace:
          root: ~/
          paths:
            - project/target/rpm/RPMS/noarch/
            - project/opennms-container/minion/images/
  horizon-deb-build:
    executor: debian-build-executor
    # Larger memory footprint required to speed up builds using Takari smartbuilder
    resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - sign-packages/install-deb-dependencies:
          skip_if_forked_pr: true
      - sign-packages/setup-env:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
      - run:
          name: Build Debian Packages
          command: |
            export NODE_OPTIONS=--max_old_space_size=1024
            export CCI_MAXCPU=4
            .circleci/scripts/makedeb.sh opennms
      - sign-packages/sign-debs:
          skip_if_forked_pr: true
          gnupg_home: ~/tmp/gpg
          gnupg_key: opennms@opennms.org
          packages: target/debs/*.deb
      - store_artifacts:
          path: ~/project/target/debs
          destination: debs
      - persist_to_workspace:
          root: ~/
          paths:
            - project/target/debs/
  horizon-publish-oci:
    executor: centos-build-executor
    steps:
      - attach_workspace:
          at: ~/
      - setup_remote_docker:
          docker_layer_caching: true
      - dockerhub-login
      - run:
          name: Load Horizon OCI image, tag it and publish to registry
          command: |
            cd opennms-container/horizon
            docker image load -i images/container.oci
            ./tag.sh
            ./publish.sh
  minion-publish-oci:
    executor: centos-build-executor
    steps:
      - attach_workspace:
          at: ~/
      - setup_remote_docker:
          docker_layer_caching: true
      - dockerhub-login
      - run:
          name: Load Minion OCI image, tag it and publish to registry
          command: |
            cd opennms-container/minion
            docker image load -i images/container.oci
            ./tag.sh
            ./publish.sh
  integration-test:
    executor: integration-test-executor
    parallelism: 4
    steps:
      - attach_workspace:
          at: ~/
      - run-integration-tests:
          rerun-failtest-count: 1
  integration-test-with-coverage:
    executor: integration-test-executor
    parallelism: 12
    steps:
      - attach_workspace:
          at: ~/
      - run-integration-tests:
          run-code-coverage: true
          rerun-failtest-count: 0
          failure-option: -fn
          changes-only: false
  code-coverage:
    executor: centos-build-executor
    resource_class: medium
    steps:
      - attach_workspace:
          at: ~/
      - restore-sonar-cache
      - run:
          name: Restore Target Directories (Code Coverage)
          when: always
          command: |
            .circleci/scripts/codecoverage-restore.sh
      - run:
          name: Run SonarQube Code Analysis
          when: always
          command: |
            export MAVEN_OPTS="-Xms3G -Xmx3G"
            .circleci/scripts/sonar.sh
      - save-sonar-cache
  smoke-test-full:
    executor: smoke-test-executor
    parallelism: 8
    # No resource class support for machine executors, we're constrained to use the default
    # medium class which has 2 vCPUs and 8 GB RAM
    #resource_class: large
    steps:
      - attach_workspace:
          at: ~/
      - run-smoke-tests
  smoke-test-minimal:
    executor: smoke-test-executor
    steps:
      - attach_workspace:
          at: ~/
      - run-smoke-tests:
          minimal: true
  create-merge-foundation-branch:
    <<: *defaults
    <<: *docker_container_config
    steps:
      - run:
          name: "Branch Merge Parameters"
          command: |
            echo "previous: << parameters.previous_branch >>, main: << parameters.main_branch >>, next: << parameters.next_branch >>"
      - when:
          condition: << parameters.next_branch >>
          steps:
            - add_ssh_keys:
                fingerprints:
                  - "5e:70:a4:1a:f3:9f:39:ca:2a:d9:b5:9a:6c:2b:c3:66"
            - cached-checkout
            - run:
                name: Create git identity
                command: |
                  git config user.email "cicd-system@opennms.com"
                  git config user.name "CI/CD System"
            - run:
                name: Checkout target branch and merge from source
                command: |
                  export GIT_MERGE_AUTOEDIT=no
                  git fetch --all
                  git checkout << parameters.next_branch >>
                  git reset --hard origin/<< parameters.next_branch >>
                  git merge origin/<< parameters.main_branch >>
            - run:
                name: Push to github
                command: git push -f origin << parameters.next_branch >>:merge-foundation/<< parameters.main_branch_label >>-to-<< parameters.next_branch_label >>

  # note, this is always run as part of the _next_ branch
  # for example, if main_branch is `foundation-2016` and next_branch is `foundation-2017`,
  # it will include the contents of the `foundation-2017` branch, thus we need to actually
  # look _backwards_ to the previous_branch and main_branch to merge the correct bits.
  merge-foundation-branch:
    <<: *defaults
    <<: *docker_container_config
    steps:
      - run:
          name: "Branch Merge Parameters"
          command: |
            echo "previous: << parameters.previous_branch >>, main: << parameters.main_branch >>, next: << parameters.next_branch >>"
      - when:
          condition: << parameters.previous_branch >>
          steps:
            - add_ssh_keys:
                fingerprints:
                  - "5e:70:a4:1a:f3:9f:39:ca:2a:d9:b5:9a:6c:2b:c3:66"
            - cached-checkout
            - run:
                name: Create git identity
                command: |
                  git config user.email "cicd-system@opennms.com"
                  git config user.name "CI/CD System
            - run:
                name: Checkout target and merge with merge branch
                command: |
                  export GIT_MERGE_AUTOEDIT=no
                  git fetch --all
                  git checkout << parameters.main_branch >>
                  git reset --hard origin/<< parameters.main_branch >>
                  git merge origin/merge-foundation/<< parameters.previous_branch_label >>-to-<< parameters.main_branch_label >>
            - run:
                name: Push to github
                command: git push origin << parameters.main_branch >>:<< parameters.main_branch >>

  publish-cloudsmith:
    executor: cloudsmith/default
    resource_class: small
    steps:
      - attach_workspace:
          at: ~/
      - publish-cloudsmith

